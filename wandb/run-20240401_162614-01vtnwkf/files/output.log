

  0%|                             | 1/51966 [00:54<792:45:10, 54.92s/it]

  0%|                             | 2/51966 [01:03<399:22:45, 27.67s/it]

  0%|                             | 3/51966 [01:04<225:15:44, 15.61s/it]
{'loss': 16.4908, 'grad_norm': 90.82154083251953, 'learning_rate': 2.8862805464691174e-09, 'epoch': 0.0}

  0%|                              | 5/51966 [01:07<97:59:03,  6.79s/it]

  0%|                              | 6/51966 [01:08<71:21:59,  4.94s/it]
{'loss': 17.4028, 'grad_norm': 69.3691635131836, 'learning_rate': 5.772561092938235e-09, 'epoch': 0.0}


  0%|                              | 8/51966 [01:19<71:59:41,  4.99s/it]
{'loss': 15.2711, 'grad_norm': 60.279212951660156, 'learning_rate': 7.696748123917645e-09, 'epoch': 0.0}


  0%|                             | 10/51966 [01:31<74:48:01,  5.18s/it]
{'loss': 15.7106, 'grad_norm': 63.90066146850586, 'learning_rate': 9.620935154897057e-09, 'epoch': 0.0}

  0%|                             | 12/51966 [01:43<76:10:02,  5.28s/it]
{'loss': 15.9253, 'grad_norm': 68.6869125366211, 'learning_rate': 1.154512218587647e-08, 'epoch': 0.0}


  0%|                             | 14/51966 [01:54<74:09:51,  5.14s/it]
{'loss': 14.6683, 'grad_norm': 62.127437591552734, 'learning_rate': 1.3469309216855879e-08, 'epoch': 0.0}


  0%|                             | 16/51966 [02:06<75:41:30,  5.25s/it]
{'loss': 17.1903, 'grad_norm': 65.34098052978516, 'learning_rate': 1.539349624783529e-08, 'epoch': 0.0}

  0%|                             | 17/51966 [02:16<94:13:17,  6.53s/it]

  0%|                             | 18/51966 [02:18<75:24:16,  5.23s/it]

  0%|                             | 20/51966 [02:29<73:00:43,  5.06s/it]
{'loss': 15.9736, 'grad_norm': 65.59159088134766, 'learning_rate': 1.9241870309794114e-08, 'epoch': 0.0}

  0%|                             | 22/51966 [02:41<72:32:27,  5.03s/it]
{'loss': 15.6644, 'grad_norm': 62.95549774169922, 'learning_rate': 2.1166057340773525e-08, 'epoch': 0.0}

  0%|                             | 24/51966 [02:53<74:25:43,  5.16s/it]

  0%|                             | 25/51966 [03:03<95:55:58,  6.65s/it]

  0%|                             | 26/51966 [03:04<72:18:03,  5.01s/it]

  0%|                             | 27/51966 [03:15<95:33:46,  6.62s/it]
{'loss': 14.9056, 'grad_norm': 60.22127151489258, 'learning_rate': 2.5976524918222055e-08, 'epoch': 0.0}


  0%|                            | 29/51966 [03:29<108:57:37,  7.55s/it]

  0%|                             | 30/51966 [03:31<81:54:27,  5.68s/it]

  0%|                             | 31/51966 [03:38<90:45:18,  6.29s/it]
{'loss': 14.6057, 'grad_norm': 58.3876838684082, 'learning_rate': 2.982489898018088e-08, 'epoch': 0.0}


  0%|                             | 34/51966 [03:51<70:47:47,  4.91s/it]
{'loss': 16.0712, 'grad_norm': 65.22813415527344, 'learning_rate': 3.174908601116029e-08, 'epoch': 0.0}
{'loss': 14.9613, 'grad_norm': 65.6569595336914, 'learning_rate': 3.2711179526649996e-08, 'epoch': 0.0}

  0%|                             | 36/51966 [04:03<72:10:28,  5.00s/it]
{'loss': 15.2957, 'grad_norm': 64.18781280517578, 'learning_rate': 3.463536655762941e-08, 'epoch': 0.0}

  0%|                             | 38/51966 [04:15<73:50:41,  5.12s/it]
{'loss': 14.8468, 'grad_norm': 61.22290802001953, 'learning_rate': 3.655955358860882e-08, 'epoch': 0.0}

  0%|                             | 40/51966 [04:27<74:28:33,  5.16s/it]

  0%|                             | 42/51966 [04:40<74:32:31,  5.17s/it]
{'loss': 14.5283, 'grad_norm': 60.93363952636719, 'learning_rate': 3.9445834135077934e-08, 'epoch': 0.0}

  0%|                             | 43/51966 [04:50<99:38:37,  6.91s/it]
{'loss': 15.0459, 'grad_norm': 61.19834518432617, 'learning_rate': 4.137002116605735e-08, 'epoch': 0.0}


  0%|                             | 46/51966 [05:04<74:11:51,  5.14s/it]
{'loss': 14.8151, 'grad_norm': 65.65514373779297, 'learning_rate': 4.3294208197036755e-08, 'epoch': 0.0}
{'loss': 15.7413, 'grad_norm': 63.562530517578125, 'learning_rate': 4.425630171252646e-08, 'epoch': 0.0}

  0%|                             | 48/51966 [05:15<73:42:44,  5.11s/it]

  0%|                             | 49/51966 [05:25<95:46:46,  6.64s/it]

  0%|                             | 50/51966 [05:27<72:28:03,  5.03s/it]

  0%|                             | 51/51966 [05:37<95:53:56,  6.65s/it]

  0%|                             | 52/51966 [05:38<72:45:34,  5.05s/it]

  0%|                                    | 53/51966 [05:49<96:20:34,  6.68s/it]

  0%|                                    | 54/51966 [05:50<73:28:30,  5.10s/it]

  0%|                                    | 55/51966 [06:01<95:59:14,  6.66s/it]
{'loss': 16.1844, 'grad_norm': 62.77793502807617, 'learning_rate': 5.291514335193381e-08, 'epoch': 0.0}

  0%|                                    | 56/51966 [06:02<73:21:39,  5.09s/it]

  0%|                                    | 58/51966 [06:13<71:38:48,  4.97s/it]
{'loss': 14.7155, 'grad_norm': 61.795406341552734, 'learning_rate': 5.580142389840293e-08, 'epoch': 0.0}

  0%|                                    | 60/51966 [06:25<72:41:42,  5.04s/it]
{'loss': 16.3921, 'grad_norm': 67.11763763427734, 'learning_rate': 5.7725610929382336e-08, 'epoch': 0.0}
  0%|                                    | 61/51966 [06:36<97:25:10,  6.76s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb3a55b7280>
Traceback (most recent call last):
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1442, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/usr/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Traceback (most recent call last):
  File "/home/ubuntu/ejpark/tevatron/src/tevatron/retriever/driver/train.py", line 112, in <module>
    main()
  File "/home/ubuntu/ejpark/tevatron/src/tevatron/retriever/driver/train.py", line 105, in main
    trainer.train()  # TODO: resume training
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/transformers/trainer.py", line 1780, in train
    return inner_training_loop(
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/transformers/trainer.py", line 2118, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ubuntu/ejpark/tevatron/src/tevatron/retriever/trainer.py", line 49, in training_step
    return super(TevatronTrainer, self).training_step(*args) / self._dist_loss_scale_factor
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/transformers/trainer.py", line 3045, in training_step
    self.accelerator.backward(loss)
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/accelerate/accelerator.py", line 2001, in backward
    loss.backward(**kwargs)
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/ubuntu/ejpark/con_venv/lib/python3.9/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt